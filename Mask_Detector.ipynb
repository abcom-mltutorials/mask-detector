{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sequential Mask_Detector ",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlJhtIC1zMef"
      },
      "source": [
        "!pip install tensorflow==2.1.0\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bl5_VHyVyvNh",
        "outputId": "c07cb214-3140-4b2e-ce5b-e5e6492856b5"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vVe92rlFAoE"
      },
      "source": [
        "# import the necessary packages\n",
        "\n",
        "from tensorflow.keras.preprocessing import image \n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "#added\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Activation\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ga7RkfeAbyqR",
        "outputId": "84e266a0-f258-49ae-d4b9-e24eb106fe8d"
      },
      "source": [
        "pip install h5py pyyaml"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (3.13)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from h5py) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNjtVkh9t7cT",
        "outputId": "b830b4c6-815f-45d2-fc3f-a17deba5a7a4"
      },
      "source": [
        "!wget https://github.com/abcom-mltutorials/mask_detector/archive/master.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-07 05:43:13--  https://github.com/abcom-mltutorials/mask_detector/archive/master.zip\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/abcom-mltutorials/mask_detector/zip/master [following]\n",
            "--2020-12-07 05:43:13--  https://codeload.github.com/abcom-mltutorials/mask_detector/zip/master\n",
            "Resolving codeload.github.com (codeload.github.com)... 140.82.114.10\n",
            "Connecting to codeload.github.com (codeload.github.com)|140.82.114.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘master.zip’\n",
            "\n",
            "master.zip              [        <=>         ]  41.52M  27.6MB/s    in 1.5s    \n",
            "\n",
            "2020-12-07 05:43:15 (27.6 MB/s) - ‘master.zip’ saved [43535909]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lP-l8C1HuG8b"
      },
      "source": [
        "! unzip master.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MZwvvLftXBm"
      },
      "source": [
        "#provide path directory and then mention both catogories for classification\n",
        "path_dir = \"/content/mask_detector-master/data\"\n",
        "categories = [\"with_mask\", \"without_mask\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9-QRvUwuooS"
      },
      "source": [
        "import io\n",
        "import requests\n",
        "from PIL import Image\n",
        "#load the data with lbs\n",
        "print(\"Loading the images\")\n",
        "# make arrays for storing dataset of images and it's label of \n",
        "# with mask and wihtout mask\n",
        "dataset = []\n",
        "lbs = []\n",
        "# join path for preprocessing of images\n",
        "for category in categories:\n",
        "    path = os.path.join(path_dir, category)\n",
        "    for img in os.listdir(path):\n",
        "      img_path = os.path.join(path, img)\n",
        "      print (img_path)\n",
        "      Img = image.load_img(img_path, target_size=(224, 224))\n",
        "      Img = image.img_to_array(Img)\n",
        "      Img = preprocess_input(Img)\n",
        "      \n",
        "      dataset.append(Img)\n",
        "      lbs.append(category)\n",
        "\n",
        "print(\"All images loaded successfully\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_43ZoomFPvB"
      },
      "source": [
        "#now convert two categories into binary format like 0,1\n",
        "label_binarizer = LabelBinarizer()\n",
        "#Fit label binarizer and transform multi-class lbs to binary lbs.\n",
        "lbs = label_binarizer.fit_transform(lbs)\n",
        "#Converts a class vector (integers) to binary class matrix\n",
        "lbs = to_categorical(lbs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IV9hRP5k5f8t"
      },
      "source": [
        "#convert images to an array\n",
        "dataset = np.array(dataset, dtype=\"float32\")\n",
        "lbs = np.array(lbs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GnHgJtC780k"
      },
      "source": [
        "#use label binarizer to split data for testing and training \n",
        "# i am using here test size of 20% and train size of 80%\n",
        "#20% data will allocate to test set generally it is 20/80 or 30/70 for test/training ratio\n",
        "# and random_state is for shuffling the data before using it to split between test and training set\n",
        "(trainX, testX, trainY, testY) = train_test_split(dataset, lbs,\n",
        "\ttest_size=0.20, stratify=lbs, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLnnAbQn8DsQ"
      },
      "source": [
        "#use augmentation to increase variation in dataset by various operation like shifting and rotating images\n",
        "data_augmentation = image.ImageDataGenerator(\n",
        "\trotation_range=20,\n",
        "\tzoom_range=0.07, #0.15->0.07\n",
        "\twidth_shift_range=0.2,\n",
        "\theight_shift_range=0.2,\n",
        "\tshear_range=0.10, #0.15->0.10\n",
        "\thorizontal_flip=True,\n",
        "\tfill_mode=\"nearest\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuwq7VxGcaYe"
      },
      "source": [
        "# input_shape is shape of image(height, width, channeli.e. 3 here RGB)\n",
        "# include_top is for fully connected layer\n",
        "# imagenet is weights from pre-trained model\n",
        "pre_trained_model = MobileNetV2(weights=\"imagenet\", include_top=False,\n",
        "\tinput_tensor=layers.Input(shape=(224, 224, 3)))\n",
        "\n",
        "# we will freeze the base model to prevent them from updation while training\n",
        "for layer in pre_trained_model.layers:\n",
        "\tlayer.trainable = True\n",
        "\n",
        "pre_trained_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BJLDoaVfKPw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9fc4701-c68e-4193-9362-a32004bf381d"
      },
      "source": [
        "#Save the last layer output\n",
        "last_layer = pre_trained_model.get_layer(\"block_14_add\")\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "last layer output shape:  (None, 7, 7, 160)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHLbUx8iBL8D"
      },
      "source": [
        "#sequential model\n",
        "model = tf.keras.Sequential(\n",
        "    [keras.Input(shape=(224, 224, 3)),\n",
        "     pre_trained_model,\n",
        "     layers.MaxPooling2D(pool_size=(2,2)),\n",
        "     layers.Dense(720, activation=\"relu\"),\n",
        "     layers.Dense(32, activation=\"relu\"),\n",
        "     layers.Dropout(0.3),\n",
        "     layers.Flatten(),\n",
        "     layers.Dense(units=2,activation=\"softmax\")\n",
        "     ] \n",
        ") \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tydL3_l7FjY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "183f3a08-8fef-48b7-afb1-d1c42940396a"
      },
      "source": [
        "# Build the model\n",
        "model.build([None, 224, 224, 3])\n",
        "#print model summary\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "mobilenetv2_1.00_224 (Functi (None, 7, 7, 1280)        2257984   \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 3, 3, 1280)        0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 3, 3, 720)         922320    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3, 3, 32)          23072     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 3, 3, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 288)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 578       \n",
            "=================================================================\n",
            "Total params: 3,203,954\n",
            "Trainable params: 3,169,842\n",
            "Non-trainable params: 34,112\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w943x0s08Wpv"
      },
      "source": [
        "# compile our model\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "#initial_learning_rate = 1e-4\n",
        "#optmzr=RMSprop(lr=initial_learning_rate, decay=initial_learning_rate / EPOCHS)\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              #optimizer=optmzr,\n",
        "              metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05CaB_1eBvUE"
      },
      "source": [
        "# Initialize values\n",
        "EPOCHS =10\n",
        "batchSize = 40"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VzLdUzk8d7s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45766051-6c6f-4a1c-9bbb-9ace678bbbcd"
      },
      "source": [
        "# train the head of the network\n",
        "FIT = model.fit(\n",
        "\tdata_augmentation.flow(trainX, trainY, batch_size=batchSize),\n",
        "\tsteps_per_epoch=len(trainX) // batchSize,\n",
        "\tvalidation_data=(testX, testY),\n",
        "\tvalidation_steps=len(testX) // batchSize,\n",
        "\tepochs= EPOCHS)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            " 2/85 [..............................] - ETA: 10s - loss: 2.5180 - accuracy: 0.5125WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0667s vs `on_train_batch_end` time: 0.1841s). Check your callbacks.\n",
            "85/85 [==============================] - 44s 518ms/step - loss: 0.1684 - accuracy: 0.9514 - val_loss: 0.7515 - val_accuracy: 0.7719\n",
            "Epoch 2/10\n",
            "85/85 [==============================] - 43s 507ms/step - loss: 0.0391 - accuracy: 0.9902 - val_loss: 1.2385 - val_accuracy: 0.8643\n",
            "Epoch 3/10\n",
            "85/85 [==============================] - 43s 504ms/step - loss: 0.0229 - accuracy: 0.9920 - val_loss: 1.9556 - val_accuracy: 0.8281\n",
            "Epoch 4/10\n",
            "85/85 [==============================] - 43s 509ms/step - loss: 0.0386 - accuracy: 0.9896 - val_loss: 0.4785 - val_accuracy: 0.9006\n",
            "Epoch 5/10\n",
            "85/85 [==============================] - 43s 503ms/step - loss: 0.0477 - accuracy: 0.9902 - val_loss: 0.0952 - val_accuracy: 0.9906\n",
            "Epoch 6/10\n",
            "85/85 [==============================] - 43s 502ms/step - loss: 0.0406 - accuracy: 0.9890 - val_loss: 0.4504 - val_accuracy: 0.9520\n",
            "Epoch 7/10\n",
            "85/85 [==============================] - 44s 520ms/step - loss: 0.0296 - accuracy: 0.9926 - val_loss: 1.4128 - val_accuracy: 0.8982\n",
            "Epoch 8/10\n",
            "85/85 [==============================] - 44s 517ms/step - loss: 0.0502 - accuracy: 0.9855 - val_loss: 0.3402 - val_accuracy: 0.9696\n",
            "Epoch 9/10\n",
            "85/85 [==============================] - 43s 510ms/step - loss: 0.0193 - accuracy: 0.9959 - val_loss: 0.8508 - val_accuracy: 0.9146\n",
            "Epoch 10/10\n",
            "85/85 [==============================] - 43s 509ms/step - loss: 0.0279 - accuracy: 0.9935 - val_loss: 0.0781 - val_accuracy: 0.9942\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNcfi-r18sbz"
      },
      "source": [
        "# predictions on the testing set\n",
        "PREDICT = model.predict(testX, batch_size=batchSize)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkY98dNz8zc-"
      },
      "source": [
        "# Make 2 lists to contain max values for predicted and actual test values\n",
        "pred_class = []\n",
        "ac_class = []\n",
        "for i in range(len(PREDICT)):\n",
        "    pr = PREDICT[i].argmax()\n",
        "    pred_class.append(pr)\n",
        "    ac = testY[i].argmax()\n",
        "    ac_class.append(ac)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iapxn_U_YO8Q"
      },
      "source": [
        "# Make 2 lists to contain the predicted and actual output results gained from \n",
        "# comparing max values in last step with alotted strings     \n",
        "output = {0:\"with_mask\", 1:\"wihout_mask\"}\n",
        "pred_op = []\n",
        "ac_op = []\n",
        "for i in range(len(pred_class)):\n",
        "   pred_op.append(output[pred_class[i]])\n",
        "   ac_op.append(output[ac_class[i]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-SVtn5_YTar",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f3c4514-1321-4b71-cab9-7ab3f31cf8a5"
      },
      "source": [
        "# Increment counter if the actual and predicted values match. Then calculate \n",
        "# % accuracy of the first batch.\n",
        "correct_pred = 0\n",
        "for i in range(batchSize):\n",
        "    if pred_op[i] == ac_op[i]:\n",
        "        correct_pred += 1\n",
        "\n",
        "print(\"Accuracy of batch = \", (correct_pred/batchSize)*100, \"%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of batch =  100.0 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UfzZzpous_s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "078d5b90-154d-46fe-91d4-c38352cfbaf9"
      },
      "source": [
        "#save model\n",
        "model.save(\"mask_detector.model\", save_format=\"h5\")\n",
        "print(\"The model is saved successfully!! Try detection by running the warn file.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model is saved successfully!! Try detection by running the warn file.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ewz7vsW94er",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4257f4f1-02df-4500-e084-12f8a39ab31a"
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}